{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITLE:  Karting Through Video Games History with Python: how to manipulate your data from Zelda to CoD\n",
    "## Author: Andrea Giussani - Data Scientist at Cloud Academy\n",
    "### Date: Nov 12, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever wondered what is the most played video game in the last thirty years? How about which gaming platform is the most used in the last decade?\n",
    "\n",
    "In this hands-on webinar, we are going to explore advanced data manipulation techniques that are typically used to translate raw data into insightful plots and charts — enabling you to answer these types of questions. To perform this analysis, we will use Python and we will explore two of the most important data analytics libraries: Pandas and Matplotlib.\n",
    "\n",
    "To get the most out of this webinar, we encourage some familiarity with Python and significant experience is helpful. For those of you new to Python, you can get your feet wet with the following Cloud Academy courses:\n",
    "\n",
    "* Working with Python\n",
    "* Python Functions, Modules, and Packages\n",
    "* Data Wrangling with Pandas\n",
    "\n",
    "At the end of this webinar, the participants will be able to:\n",
    "\n",
    "* Understand the main functionalities of Pandas for data manipulation\n",
    "* Plot raw data into nice looking charts in Python using Matplotlib\n",
    "* Complete a data analytics pipeline for exploratory data analysis\n",
    "\n",
    "Participants are strongly encouraged to download the needed data from the following [Github repo](https://github.com/cloudacademy/ca_webinar_video_games_analysis).\n",
    "\n",
    "You can follow along with the webinar by using either your favorite local Python or Google Colab environment. For more details, please check the readme on the aforementioned Github repo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Manipulation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the file `'data/vgsales.csv'` using the pandas `read_csv()` function, and store it into the variable `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the overall composition of the dataset using the `.info()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Cleaning\n",
    "\n",
    "We clearly see there exists a few null values among both the `Publisher` and `Year` columns. The strategy here is to remove them. <br>\n",
    "Let us remove the null values using the pandas `.dropna()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was generated at the end of the year 2016. Hence, each observation with an occurrence greater than or equal to 2017 must be considered as either corrupted or incorrect, and hence must be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving to a proper data analysis, we need to be sure the data is consistent. By consistency I mean an intrinsic characteristic of the data. For instance, the `Publisher` name might contain a typo, or sometimes a Publisher might be identified by several names. \n",
    "\n",
    "To investigate this, let us check how `Sony` appears inside our dataset: we hence access to the `Publisher` column, which is of type object, and try to check the different names `Sony` is used for: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the Sony Publisher identifier is not homogeneously identified among observations.\n",
    "\n",
    "We might think of, say, changing `“Sony Computer Entertainment”`, `“Sony Computer Entertainment America”`, `“Sony Computer Entertainment Europe”`, `“Sony Music Entertainment”` and `“Sony Online Entertainment”` to `“Sony”`.\n",
    "\n",
    "To do this, we basically create a custom method, called `merging_info_publisher`, that should be called whenever we wish to perform such kind of cleaning on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "def merging_info_publisher(data: pd.DataFrame, publisher: str):\n",
    "    data.loc[data['Publisher'].str.contains(publisher, case=False), 'Publisher'] = publisher\n",
    "    return data[data['Publisher'].str.contains(publisher, case=False)]['Publisher'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly, this pattern is repeated for different publishers as well. Here we identify a few Publishers that might have different labels inside the dataset, and we apply the `merging_info_publisher` method for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "publishers = ['Sony', 'Nintendo', 'Ubisoft', 'Activision', 'Electronic Arts', 'Konami']\n",
    "for publisher in publishers:\n",
    "    merging_info_publisher(data, publisher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check now how `\"Sony\"` is mapped inside our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "data[data['Publisher'].str.contains('Sony')]['Publisher'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extra control is to convert `EA Sports` to `Electronic Arts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "data.loc[data['Publisher'].str.contains('EA Sports', case=False), 'Publisher'] = 'Electronic Arts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, convert `['Bandai', 'Namco Bandai', 'Namco', 'Namco Bandai Games' ]` to `Namco`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "namco_names = ['Bandai', 'Namco Bandai', 'Namco', 'Namco Bandai Games' ]\n",
    "data.loc[data['Publisher'].str.contains('|'.join(namco_names), case=False), 'Publisher'] = 'Namco'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the absolute distribution of the top 20 Publishers in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remove the Publisher called `\"Unknown\"`: this is not obviously fine. Store the result into the global variable `filtered_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Total Games Released Each Year\n",
    "\n",
    "We now want to know when the video game industry experienced a drastic development. Based on the number of games released each year, we might find out when the video games boom happened. We store the distribution of video games releases by year inside the variable `counter_df_by_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us embed that dataframe into a graphical dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Games')\n",
    "ax.set_title('Evolution of Video Games Industry')\n",
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been a significant boom in the late 2000s. Nowadays, the distinct number of release have shrunken possibly due to a more convergence to popular titles by both customers and developers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Publisher Analysis with respect to Global Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of considering absolute frequencies (with respect to the number of video games releases) of the top publishers, a better proxy is to consider the top publishers by Global Sales, identified by the columns `\"Global_sales\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "total_sales_df = filtered_data[['Global_Sales', 'Publisher']].drop_duplicates().groupby('Publisher').sum()\n",
    "top_10_sales = total_sales_df.sort_values(by='Global_Sales', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Graphical Representation of the Publishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again embed the above dataset into a graphical dimension to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understand the most popular Platform by Year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": false
   },
   "source": [
    "We now want to go further and try to see which Platform was the most popular for each Year. To do so, we again use a proxy the total Global Sales with respect to video games for each specific Platform. \n",
    "\n",
    "However, this requires a little bit of data wrangling, and therefore we need to perform a few steps to be able to answer to this question.\n",
    "\n",
    "First of all, we count the number of video games by Platform using the `.groupby()` method, and we store the result into the variable `most_popular_platforms`. This has been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "most_popular_platforms = filtered_data[['Name','Platform']].drop_duplicates().groupby('Platform').count()\n",
    "most_popular_platforms.rename(columns={'Name': 'Total Observations'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need two steps:\n",
    "* store inside the variable `top20_platforms` the top 20 platform with respect to the column `Total Observations`;\n",
    "* filter the `filtered_data` with those Platforms. Store the result into `filtered_data_top20`.\n",
    "\n",
    "This has been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "top_20_platforms = most_popular_platforms.sort_values(by='Total Observations', ascending=False).head(20)\n",
    "filtered_data_top20 = filtered_data[filtered_data['Platform'].isin(list(top_20_platforms.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate the data with respect to Global Sales using the pandas `.pivot_table()`. We would like to have, as columns, the platforms' vendor and, as index, the year. Store the result into the `pivoted_data_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is a little bit tricky and it has been already prefilled for you. \n",
    "We now want to find the `Platform` which has the top sell for each distinct year. To do that we employ the `NumPy` method `argsort()` which basically allows to sort, for each row, the observations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "rows_arrangement = np.argsort(-pivoted_data_df.values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then select the column names based on the sorting operation, so that in the first place we will find the platform with highest value with respect to the aggregated Global Sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "data_platform_by_year = pd.DataFrame(pivoted_data_df.columns[rows_arrangement], index=pivoted_data_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Distribution of the most popular platforms during the last 40 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results inside the variable `most_popular_platform_by_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Which was the most popular game in each Year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the resulting dataframe object into the variable `most_popular_games`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
    "most_popular_games = pd.DataFrame()\n",
    "\n",
    "for _, row in most_popular_platform_by_year.iterrows():\n",
    "    year = row['Year']\n",
    "    platform = row['Platform']\n",
    "    \n",
    "    inner_df = filtered_data.query(\"Year == @year & Platform==@platform\")\n",
    "    \n",
    "    pivoted_table_year_platform = inner_df.pivot_table(\n",
    "        index = 'Year',\n",
    "        columns='Name',\n",
    "        values='Global_Sales',\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    temp_col_max_value = pivoted_table_year_platform.max(axis=1).to_frame() # finds max value by row\n",
    "    temp_col_max_value.rename(columns={0:'Total sells (ML of units)'}, inplace=True)\n",
    "    \n",
    "    temp_col_max = pivoted_table_year_platform.idxmax(axis=1).to_frame() # find the column with the greatest value on each row\n",
    "    temp_col_max.rename(columns={0:'Most Wanted Title'}, inplace=True)\n",
    "    \n",
    "    merging_dfs = pd.concat([temp_col_max, temp_col_max_value], axis=1)\n",
    "    \n",
    "    most_popular_games = most_popular_games.append(merging_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Which was the most sold Title by Platform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new object, called `most_popular_vg_by_platform`, that join the information from `most_popular_platfrom_by_year` and `most_popular_games`. Print the result in console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Which are the most sold videogames ever?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interesting in investigating which were the most sold titles in the last 40 years. To do so, we employ the `.groupby()` method, and store the result into the `most_wanted_vg` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# TO BE FILLED\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the nintendo games are the most sold! The Wii sports was such a huge success for Nintendo. The classic “Mario” games own 4 of Top 10 most popular games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webinar",
   "language": "python",
   "name": "webinar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
